{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('IUA')",
   "display_name": "Python 3.8.5 64-bit ('IUA')",
   "metadata": {
    "interpreter": {
     "hash": "31e8c18851cc2616071ca7e5dcdbafd0634b8d1e2e632646433bf1c202497ec9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Zadanie projektu\n",
    "\n",
    "V tejto fáze sa od Vás očakáva:\n",
    "\n",
    "**Základný opis dát spolu s ich charakteristikami (5b).**\n",
    "\n",
    "Pre dosiahnutie plného počtu bodov uveďte\n",
    "\n",
    "- počet záznamov,\n",
    "- počet atribútov,\n",
    "- ich typy,\n",
    "- pre zvolené významné atribúty ich distribúcie, základné deskriptívne štatistiky a pod.\n",
    "\n",
    "**Párová analýza dát (5b).**\n",
    "\n",
    "- Preskúmajte vzťahy medzi zvolenými dvojicami atribútov.\n",
    "- Identifikujte závislostí medzi dvojicami atribútov (napr. korelácie) a na závislosti medzi predikovanou premennou a ostatnými premennými (potenciálnymi prediktormi).\n",
    "\n",
    "**Formulácia a štatistické overenie hypotéz o dátach (2b).**\n",
    "\n",
    "- Mali by ste sformulovať aspoň dve hypotézy o dátach, ktoré budú relevantné v kontexte zadanej predikčnej úlohy. Príkladom hypotézy v doméne (v závislosti od pridelenej dátovej sady) môže byť, napr. *pacienti s chorobou štítnej žľazy majú v priemere inú (vyššiu/nižšiu) hodnotu nejakej látky alebo hormónu ako pacienti bez danej choroby*.\n",
    "- Vami sformulované hypotézy overte vhodne zvoleným štatistickým testom.\n",
    "\n",
    "**Identifikácia problémov v dátach spolu s predpokladaným scenárom riešenia v ďalšej fáze (4b).**\n",
    "\n",
    "Identifikujte, čo a ako budete musieť v rámci predspracovania vyriešiť v ďalšej fáze, napr.:\n",
    "\n",
    "- nevhodná štruktúra dát (dáta nie sú v tabuľkovej podobe alebo jedna entita je opísaná viacerými riadkami tabuľky)\n",
    "- duplicitné záznamy, resp. nejednoznačné mapovanie medzi záznamami\n",
    "- nejednotné formáty dát\n",
    "- chýbajúce hodnoty\n",
    "- vychýlené (odľahlé) hodnoty\n",
    "- v dátach sa môžu nachádzať aj iné, tu nevymenované problémy.\n",
    "\n",
    "**V odovzdanej správe (`Jupyter Notebooku`) by ste tak mali vedieť zodpovedať na otázky**\n",
    "\n",
    "- Majú dáta vhodný formát pre ďalšie spracovanie? Ak nie, aké problémy sa v nich vyskytujú?\n",
    "- Sú niektoré atribúty medzi sebou závislé? Od ktorých (jednotlivých) atribútov závisí predikovaná premenná?\n",
    "- Sú v dátach chýbajúce hodnoty? Ako sú reprezentované? Ako plánujete riešiť problém chýbajúcich hodnôt pre jednotlivé atribúty, resp. pozorovania? (Pre rôzne atribúty môže byť vhodné použiť rôzne stratégie.)\n",
    "- Nadobúdajú niektoré atribúty nezmyselné (nekonzistentné) či inak výrazne odchýlené hodnoty? Ktoré?\n",
    "- Ako plánujete v ďalšej fáze tieto identifikované problémy adresovať / riešiť?\n",
    "\n",
    "> Správa sa odovzdáva v 6. týždni semestra na cvičení. Dvojica svojmu cvičiacemu odprezentuje vykonanú prieskumnú analýzu v Jupyter Notebooku). Následne správu elektronicky odovzdá jeden člen z dvojice do systému AIS do nedele 01.11.2020 23:59."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as py\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats as sm_stats\n",
    "import statsmodels.stats.api as sms\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import var\n",
    "from math import sqrt\n",
    "from numpy import cov\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data = pd.read_csv(\"Dataset/personal_train.csv\")\n",
    "other_data = pd.read_csv(\"Dataset/other_train.csv\")"
   ]
  },
  {
   "source": [
    "## Základné informácie o datasetoch\n",
    "Dataset personal_data:\n",
    "* Veľkosť: 3933 záznamov\n",
    "* Počet stĺpcov: 6\n",
    "* Typy stĺpcov sú uvedené nižsie(získané pomocou dataset.info())\n",
    "* **Tento dataset néma žiadne duplicitné či chýbajúce dáta**\n",
    "* Dôležité štatistické atribúty:\n",
    "*    * Vek(age)\n",
    "*    * Pohlavie(sex)\n",
    "\n",
    "Vlastnosti štatistických atribútov uvedené nižšie (získané pomocou dataset\\['atribute'\\].describe())\n",
    "\n",
    "Dataset personal_data:\n",
    "* Veľkosť: 3983 záznamov\n",
    "* Počet stĺpcov: 23\n",
    "* Typy stĺpcov sú uvedené nižsie(získané pomocou dataset.info())\n",
    "* **Tento dataset obsahuje značné množstvo duplicitných či chýbajúcich dát**\n",
    "* Dôležité štatistické atribúty:\n",
    "*    * Krajina pôvodu(native-country)\n",
    "*    * Rasa(race)\n",
    "*    * Vzťahy(relationship)\n",
    "*    * Priemerné O2 (mean_oxygen)\n",
    "*    * Tehotenstvo (pregnant)\n",
    "\n",
    "Vlastnosti štatistických atribútov uvedené nižšie (získané pomocou dataset\\['atribute'\\].describe())\n",
    "\n",
    "Obsahom datasetu other_data je aj atribút medical_info ktorý obsahuje reťazec podobný formátu JSON s ďaľšími atribútmi ktoré môžu byť štatisticky doležité a preto bol tento reťazec extraktovaný a v spojení s atribútom name z datasetu other_data pridaný do samostatného datasetu medical_info_dataset. \n",
    "\n",
    "*Poznámka: Boli pridávané iba záznamy pre jedičné hodnoty atribútu name a s nenulovým atribútom medical_info*\n",
    "\n",
    "Dataset medical_info_dataset:\n",
    "* Veľkosť: 3927 záznamov\n",
    "* Počet stĺpcov: 5\n",
    "* Typy stĺpcov sú uvedené nižsie(získané pomocou dataset.info())\n",
    "\n",
    "Všetky atribúty tohto datasetu sú štatisticky dôležité a ich vlastnosti sú uvedené nižsie (získané pomocou dataset\\['atribute'\\].describe())\n",
    "\n",
    "Všetky vyššie spomenuté datasety sme spojili do jedného datasetu pre možnosť jednoduchšie pracovať so všetkými dôležitými dátami\n",
    "\n",
    "Dataset usefull_dataset:\n",
    "* Veľkosť: 3933 záznamov\n",
    "* Počet stĺpcov: 29\n",
    "* Typy stĺpcov sú uvedené nižsie(získané pomocou dataset.info())"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Unnamed: 0' in personal_data:\n",
    "    del personal_data['Unnamed: 0']\n",
    "if 'Unnamed: 0' in other_data:\n",
    "    del other_data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data['sex'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data['native-country'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data['race'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data['relationship'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data['mean_oxygen'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data['pregnant'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subset with only unique names\n",
    "unique_names_dataset = other_data.drop_duplicates('name')\n",
    "unique_names_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset from 'medical_info' attribute\n",
    "medical_data_objects = []\n",
    "for index, record in unique_names_dataset.iterrows():\n",
    "    if isinstance(record['medical_info'], float):\n",
    "        continue\n",
    "    medical_object = json.loads(record['medical_info'].replace(\"\\'\", '\\\"').replace(':\\\"',':').replace('\\\",',',').replace('\\\"}','}'))\n",
    "    medical_object['name'] = record['name']\n",
    "    medical_data_objects.append(medical_object)\n",
    "medical_info_dataset = pd.DataFrame(medical_data_objects)\n",
    "medical_info_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_info_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(medical_info_dataset[(medical_info_dataset['mean_glucose'] > 0) & (medical_info_dataset['mean_glucose'] < 300)].mean_glucose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names in personal_data and unique_names_dataset are equal on equal positions\n",
    "personal_data['name'].isin(unique_names_dataset['name']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets to create single large dataset with usefull data so it's easier to create graphs and analysis\n",
    "merged_medical_info_dataset = unique_names_dataset.merge(medical_info_dataset, on=['name'], how='outer').drop('medical_info', axis='columns')\n",
    "usefull_dataset = personal_data.merge(merged_medical_info_dataset, on=['name', 'address'], how='outer')\n",
    "usefull_dataset.info()"
   ]
  },
  {
   "source": [
    "### Distribúcia veku podľa pohlavia"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two subsets for records of Male and Female age\n",
    "male_age = usefull_dataset[(usefull_dataset['sex'] == \" Male\") & (usefull_dataset['age'] > 0)]\n",
    "female_age = usefull_dataset[(usefull_dataset['sex'] == \" Female\") & (usefull_dataset['age'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare distribution of age of male and female dataset\n",
    "sns.distplot(male_age['age'])\n",
    "sns.distplot(female_age['age'])\n",
    "usefull_dataset[usefull_dataset['age'] > 0].groupby(['sex'])['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether male and female datasets are from distributions of equal variances\n",
    "age_sex_levene_test = stats.levene(male_age['age'], female_age['age'])\n",
    "print(age_sex_levene_test)\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if age_sex_levene_test.pvalue > alpha:\n",
    "    print('Equal variances (fail to reject H0)')\n",
    "else:\n",
    "    print('Another variances (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether male and female datasets are from equal distributions\n",
    "age_sex_student_ttest, p = stats.ttest_ind(male_age['age'], female_age['age'])\n",
    "print('Statistics=%.3f, p=%.3f' % (age_sex_student_ttest, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "source": [
    "### Ditribúcia týždenných hodín podľa pohlavia"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_hours = usefull_dataset[(usefull_dataset['sex'] == \" Female\") & (usefull_dataset['hours-per-week'] > 0)]\n",
    "male_hours = usefull_dataset[(usefull_dataset['sex'] == \" Male\") & (usefull_dataset['hours-per-week'] > 0)]\n",
    "sns.distplot(male_hours['hours-per-week'])\n",
    "sns.distplot(female_hours['hours-per-week'])\n",
    "usefull_dataset[usefull_dataset['hours-per-week'] > 0].groupby(['sex'])['hours-per-week'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether male and female datasets are from distributions of equal variances\n",
    "hours_sex_levene_test = stats.levene(male_hours['hours-per-week'], female_hours['hours-per-week'])\n",
    "print(hours_sex_levene_test)\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if hours_sex_levene_test.pvalue > alpha:\n",
    "    print('Equal variances (fail to reject H0)')\n",
    "else:\n",
    "    print('Another variances (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test whether male and female datasets are from equal distributions\n",
    "hours_sex_student_ttest, p = stats.ttest_ind(male_hours['hours-per-week'], female_age['hours-per-week'])\n",
    "print('Statistics=%.3f, p=%.3f' % (hours_sex_student_ttest, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "source": [
    "## Identifikácia problémov s dátami v datasetoch\n",
    "\n",
    "Medzi problemy s nevhodnou strukturou dat by som radil adresu ktora je cela ulozena ako string. Tieto data mohly byt ulozene ako json a dalo by sa s nimi lahsie pracovat. Napriklad keby chceme graf o udajoch podla statu musime si ich najpv vybrat zo stringu."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_one = personal_data['address'].str.split(', ',expand=True)[0]\n",
    "column_two_and_three = personal_data['address'].str.split(', ',expand=True)[1]\n",
    "column_two = column_two_and_three.str.split(' ',expand=True)[0]\n",
    "column_three = column_two_and_three.str.split(' ',expand=True)[1]\n",
    "\n",
    "personal_data['address'] = column_one\n",
    "personal_data['state'] = column_two\n",
    "personal_data['postal_code'] = column_three\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.displot(data=personal_data['state'].dropna(),aspect = 5)"
   ]
  },
  {
   "source": [
    "dalsi problem s datami je ze medzi personal_data sa nachadzaju neplatne data ako napriklad osoba ktora ma -1 rokov"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data.age.min()"
   ]
  },
  {
   "source": [
    "Problem je aj s nekonzistenciov formatovania datumov kde hned prvy je inak formatovany ako ostatne\n",
    "a to nehovoriac o tom ze kolonka vek nekoresponduje s datumom narodenia. jedine ze by tam boli aj datumy z historie ako napriklad rok narodenia 55"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data[[\"date_of_birth\",\"age\"]]"
   ]
  },
  {
   "source": [
    "Pri Medical_data su problemy s datamy trosku ine napriklad ma nulove hodnoty kde vsetky zaznamy su len z mien a adries inak kazda kategoria ma nejake null hodnoty"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data.info()"
   ]
  },
  {
   "source": [
    "Dalsi problem s other_data je ze data pre medical info sa tvaria ze su JSON ale niesu koli tomu ze pouzivaju jednoite uvodzovky "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data.medical_info[0]"
   ]
  },
  {
   "source": [
    "takysto ako pri personal data tak aj pri other_data sa v datach nachadzaju nezmysli ako napriklad ze musi su tehotny"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_data[other_data['pregnant'] == \"t\"]"
   ]
  },
  {
   "source": [
    "medzi dalsie problemy datasetu other_data radim nazvy atributov ktore casto nemaju ziadny vyznam alebo je nedostacujuci na pochopenie o com hovori\n",
    "\n",
    "celkovo v other_data sa nachadza vela Null hodnot ktore budeme naskor riesit tak ze patricny riadok budeme ignorovat s pouzitim Pairwise deletion toto budeme pouzivat aj pri neplatnych datach ktore boli opisovane vyssie"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usefull_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(usefull_dataset[['race', 'std_oxygen', 'std_glucose', 'skewness_oxygen', 'skewness_glucose', 'kurtosis_oxygen', 'kurtosis_glucose', 'mean_oxygen', 'mean_glucose', 'native-country', 'class', 'age', 'hours-per-week', 'sex']], hue='sex')"
   ]
  },
  {
   "source": [
    "## Nulova hypoteza ludia s odchylkou glukozy od priemeru maju vacsiu pravdepodobnost mat cukrovku\n",
    "## Alternativna nulova hypoteza ludia s odchylkou glukozy od priemeru maju vacsiu pravdepodobnost mat cukrovku\n",
    "\n",
    "### Overenie predpokladov\n",
    "#### Predpoklad normálnosti rozdelenia\n",
    "Na overenie normálnosti vieme použiť aj Shapiro-Wilkov test, ktorý testuje nulovú hypotézu, že dáta pochádzajú z normálneho rozdelenia. Ak je  \n",
    "p < 0,05, nulovú hypotézu zamietame a dáta pravdepodobne pochádzajú z iného ako normálneho rozdelenia. Ak je  p > 0,05, nulovú hypotézu nezamietame, \n",
    "teda na základe dát nemôžeme prehlásiť, že by dáta pochádzali z iného, ako normálneho rozdelenia."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = usefull_dataset[(usefull_dataset['class'] >= 0) & (usefull_dataset['skewness_glucose'] > 0)]['class']\n",
    "skew_data = usefull_dataset[(usefull_dataset['class'] >= 0) & (usefull_dataset['skewness_glucose'] > 0)]['skewness_glucose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(class_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(skew_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro_test = stats.shapiro(class_data)\n",
    "print(shapiro_test)\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if shapiro_test.pvalue > alpha:\n",
    "    print('Normal distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Another distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro_test = stats.shapiro(skew_data)\n",
    "print(shapiro_test)\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if shapiro_test.pvalue > alpha:\n",
    "    print('Normal distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Another distributions (reject H0)')"
   ]
  },
  {
   "source": [
    "#### Nakolko pvalue pri class_data a aj pri skewness_data je menej ako 0.05 musime pouzit Mann-Whitneyho U-test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Mann-Whitney U test\n",
    "\n",
    "Similar to T-test, but non-parametric for at least 20 observations in each data sample.\n",
    "\n",
    "**Hypothesis**\n",
    "- $H_0$ = no difference between the distributions of the data samples \n",
    "- **Fail to Reject $H_0$**: Sample distributions are equal \n",
    "- **Reject $H_0$**: Sample distributions are not equal"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare samples\n",
    "stat, p = stats.mannwhitneyu(skew_data, class_data) \n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)') \n",
    "else:\n",
    "    print('Different distribution (reject H0)')"
   ]
  },
  {
   "source": [
    "## Statistical power"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cohen's d for independent samples\n",
    "def cohend(d1, d2):\n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2) \n",
    "    \n",
    "    # calculate the variance of the samples\n",
    "    s1, s2 = var(d1, ddof=1), var(d2, ddof=1)\n",
    "\n",
    "    # calculate the pooled standard deviation\n",
    "    s = sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2)) \n",
    "    \n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = mean(d1), mean(d2)\n",
    "    \n",
    "    # calculate the effect size\n",
    "    d = (u1 - u2) / s \n",
    "    return d\n",
    "\n",
    "cd = cohend(skew_data, class_data)\n",
    "print('Cohens d value: %f' % cd)\n",
    "# interpret\n",
    "if 0.2 <= cd < 0.5:\n",
    "    print('Small effect - Cohens d value: %f' % cd)\n",
    "elif 0.5 <= cd < 0.8:\n",
    "    print('Medium effect - Cohens d value: %f' % cd)\n",
    "elif 0.8 <= cd:\n",
    "    print('Large effect - Cohens d value: %f' % cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "sns.distplot(class_data, bins=10)\n",
    "sns.distplot(skew_data, bins=10)\n",
    "\n",
    "# calculate covariance matrix\n",
    "covariance = cov(skew_data, class_data)[0, 1]\n",
    "print(covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'observation': np.repeat([True, False], len(class_data)), \n",
    "                   'score': np.concatenate((skew_data, class_data))})\n",
    "sns.boxplot('observation', 'score', data=df)"
   ]
  },
  {
   "source": [
    "Podla vysledkov by malo byt jasne ze nasa hypoteza je pravdiva ale nemusi byt ochorenie az prilis zavysle od odchylky glukozy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Parova analyza"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Analyza odchylky glukozy a odchylky kyslika"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skew_oxy_ana = usefull_dataset['skewness_oxygen']\n",
    "skew_glu_ana = usefull_dataset['skewness_glucose']\n",
    "class_ana = usefull_dataset['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.scatterplot(x=skew_glu_ana,y=skew_oxy_ana,hue=class_ana,palette=['r','g'])"
   ]
  },
  {
   "source": [
    "pri parovom grafe odchylky glukozy a odchylky kyslika mozme vidiet ze pokial mal pacient odchylku jedneho nemal odchylky v druhom. Co moze znamenat ze od seba nejakt tieto daza zavysia ale moze to byt aj nahodou."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=skew_oxy_ana, y=skew_glu_ana,scatter_kws={\"color\": \"red\"}, line_kws={\"color\": \"green\"})\n",
    "print(\"Pearson correlation: %.3f\" % skew_oxy_ana.corr(skew_glu_ana))"
   ]
  },
  {
   "source": [
    "Ked za pozrieme na koleraciu vidim e je negativna a jej absolutna hodnota nieje prave najvsysie co znamena ze je medzi tymito datami korelacia ale nieje az taka signifikantna"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(skew_oxy_ana,bins=10)\n",
    "sns.distplot(skew_glu_ana,bins=10)\n",
    "\n",
    "cd = cohend(skew_oxy_ana, skew_glu_ana)\n",
    "print('Cohens d value: %f' % cd)\n",
    "\n",
    "# interpret\n",
    "if 0.2 <= cd < 0.5:\n",
    "    print('Small effect - Cohens d value: %f' % cd)\n",
    "elif 0.5 <= cd < 0.8:\n",
    "    print('Medium effect - Cohens d value: %f' % cd)\n",
    "elif 0.8 <= cd:\n",
    "    print('Large effect - Cohens d value: %f' % cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.scatterplot(x=skew_glu_ana,y=class_ana,hue=class_ana,palette=['r','g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=skew_glu_ana, y=class_ana,scatter_kws={\"color\": \"red\"}, line_kws={\"color\": \"green\"})\n",
    "print(\"Pearson correlation: %.3f\" % class_ana.corr(skew_glu_ana))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(skew_glu_ana,bins=10)\n",
    "sns.distplot(class_ana,bins=10)\n",
    "\n",
    "cd = cohend(skew_glu_ana, class_ana)\n",
    "print('Cohens d value: %f' % cd)\n",
    "\n",
    "# interpret\n",
    "if 0.2 <= cd < 0.5:\n",
    "    print('Small effect - Cohens d value: %f' % cd)\n",
    "elif 0.5 <= cd < 0.8:\n",
    "    print('Medium effect - Cohens d value: %f' % cd)\n",
    "elif 0.8 <= cd:\n",
    "    print('Large effect - Cohens d value: %f' % cd)"
   ]
  }
 ]
}