{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as py\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats as sm_stats\n",
    "import statsmodels.stats.api as sms\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import var\n",
    "from math import sqrt\n",
    "import re\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_data = pd.read_csv(\"Dataset/personal_train.csv\")\n",
    "other_data = pd.read_csv(\"Dataset/other_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Unnamed: 0' in personal_data:\n",
    "    del personal_data['Unnamed: 0']\n",
    "if 'Unnamed: 0' in other_data:\n",
    "    del other_data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 3933 entries, 0 to 3982\nData columns (total 22 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   name             3933 non-null   object \n 1   address          3933 non-null   object \n 2   kurtosis_oxygen  3929 non-null   float64\n 3   occupation       3926 non-null   object \n 4   marital-status   3925 non-null   object \n 5   pregnant         3929 non-null   object \n 6   education-num    3535 non-null   float64\n 7   relationship     3926 non-null   object \n 8   std_oxygen       3925 non-null   float64\n 9   capital-gain     3928 non-null   float64\n 10  skewness_oxygen  3925 non-null   float64\n 11  education        3926 non-null   object \n 12  fnlwgt           3928 non-null   float64\n 13  class            3923 non-null   float64\n 14  income           3927 non-null   object \n 15  medical_info     3933 non-null   object \n 16  native-country   3931 non-null   object \n 17  capital-loss     3927 non-null   float64\n 18  mean_oxygen      3927 non-null   float64\n 19  hours-per-week   3929 non-null   float64\n 20  race             3679 non-null   object \n 21  workclass        3925 non-null   object \ndtypes: float64(10), object(12)\nmemory usage: 706.7+ KB\n"
     ]
    }
   ],
   "source": [
    "unique_medical_name_dataset = other_data.dropna(subset=['medical_info']).drop_duplicates('name')\n",
    "unique_medical_name_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3933 entries, 0 to 3932\nData columns (total 5 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   mean_glucose      3933 non-null   float64\n 1   std_glucose       3933 non-null   float64\n 2   kurtosis_glucose  3933 non-null   float64\n 3   skewness_glucose  3933 non-null   float64\n 4   name              3933 non-null   object \ndtypes: float64(4), object(1)\nmemory usage: 153.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# create a dataset from 'medical_info' attribute\n",
    "medical_data_objects = []\n",
    "for index, record in unique_medical_name_dataset.iterrows():\n",
    "    if isinstance(record['medical_info'], float):\n",
    "        continue\n",
    "    medical_object = json.loads(record['medical_info'].replace(\"\\'\", '\\\"').replace(':\\\"',':').replace('\\\",',',').replace('\\\"}','}'))\n",
    "    medical_object['name'] = record['name']\n",
    "    medical_data_objects.append(medical_object)\n",
    "medical_info_dataset = pd.DataFrame(medical_data_objects)\n",
    "medical_info_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 3933 entries, 0 to 3932\nData columns (total 28 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   name              3933 non-null   object \n 1   address           3933 non-null   object \n 2   age               3933 non-null   int64  \n 3   sex               3933 non-null   object \n 4   date_of_birth     3933 non-null   object \n 5   kurtosis_oxygen   3929 non-null   float64\n 6   occupation        3926 non-null   object \n 7   marital-status    3925 non-null   object \n 8   pregnant          3929 non-null   object \n 9   education-num     3535 non-null   float64\n 10  relationship      3926 non-null   object \n 11  std_oxygen        3925 non-null   float64\n 12  capital-gain      3928 non-null   float64\n 13  skewness_oxygen   3925 non-null   float64\n 14  education         3926 non-null   object \n 15  fnlwgt            3928 non-null   float64\n 16  class             3923 non-null   float64\n 17  income            3927 non-null   object \n 18  native-country    3931 non-null   object \n 19  capital-loss      3927 non-null   float64\n 20  mean_oxygen       3927 non-null   float64\n 21  hours-per-week    3929 non-null   float64\n 22  race              3679 non-null   object \n 23  workclass         3925 non-null   object \n 24  mean_glucose      3933 non-null   float64\n 25  std_glucose       3933 non-null   float64\n 26  kurtosis_glucose  3933 non-null   float64\n 27  skewness_glucose  3933 non-null   float64\ndtypes: float64(14), int64(1), object(13)\nmemory usage: 891.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# merge datasets to create single large dataset with usefull data so it's easier to create graphs and analysis\n",
    "merged_medical_info_dataset = unique_medical_name_dataset.merge(medical_info_dataset, on=['name'], how='outer').drop('medical_info', axis='columns')\n",
    "usefull_dataset = personal_data.merge(merged_medical_info_dataset, on=['name', 'address'], how='outer')\n",
    "usefull_dataset.info()"
   ]
  }
 ]
}